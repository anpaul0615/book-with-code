# 4장 머신러닝의 기본 요소


## 4.1. 머신러닝의 네가지 분류

- 지도학습, 비지도학습, 자기지도학습, 강화학습

- 지도학습 :  
  샘플데이터가 주어지면 알고있는 타깃에 입력데이터를 매핑하는 방법을 학습하는 방법임.  
  광학문자판독, 음성인식, 언어번역 등 대부분의 딥러닝 응용분야가 지도학습 기반으로 구현됨.  
  대부분의 경우에 분류와 회귀로 구성되지만 시퀀스생성, 구문트리예측, 물체감지, 이미지분할 등 과 같은 특이한 변종도 있음.

- 비지도학습 :  
  어떠한 타깃도 사용하지 않고 입력데이터에 대한 흥미로운 변환을 찾는 방법임.  
  데이터에 있는 상관관계를 더 잘 이해하기 위해 사용함.  
  종종 지도학습 문제를 풀기 전에 데이터세트를 더 잘 이해하기 위해 필수적으로 거치는 단계로 사용됨.  
  차원축소, 군집 등이 비지도학습에서 잘 알려진 범주임.

- 자기지도학습 :  
  지도학습이지만, 사람이 만든 레이블을 사용하지 않는 지도학습임.  
  즉 학습과정에 사람이 개입하지 않는 지도학습.  
  경험적인 알고리즘을 사용해서 입력데이터로부터 생성된 레이블을 사용함.  
  예를들어 오토인코더(autoencoder), 지난 프레임이 주어졌을때 비디오의 다음 프레임을 예측하기, 이전단어가 주어졌을때 다음단어를 예측하기 등이 자기지도학습의 예임.  
  지도학습, 자기지도학습, 비지도학습 은 명확한 경계가 없고 연속적이기 때문에, 학습 메커니즘과 애플리케이션 측면 중 어디에 중점을 두는지에 따라 재해석될수있음.

- 강화학습 :  
  에이전트라는 학습 주체를 만들고, 이 에이전트를 환경에 대한 정보를 받아 보상을 최대한으로 얻는 행동을 선택하도록 학습시키는 방법임.  
  예를들어 비디오게임화면을 입력으로 받고, 게임점수를 최대화하는 행동을 학습하도록하여, 게임 내의 에이전트의 행동을 출력하도록 구성함.  
  아직까지 게임 이외의 실제적인 성공사례는 없지만, 앞으로 자율주행자동차, 자원관리, 교육 등에서 좋은 성과를 보일것으로 기대함.

- ※ 분류와 회귀에서 사용하는 용어 정리  
  샘플(=입력) : 모델에 주입될 하나의 데이터포인트  
  예측(=출력) : 모델로부터 나오는 값  
  타깃 : 모델이 완벽하게 예측해야 하는값  
  예측오차(=손실값) : 모델의 예측과 타깃 사이의 차이값  
  레이블 : 분류문제에서 클래스 할당의 구체적인 사례  
  클래스 : 분류문제에서 데이터포인트가 선택가능한 범주들의 집합



## 4.2. 머신러닝 모델 평가

- 머신러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는것임.  
  모델의 일반화 성능에 대한 신뢰할수있는 측정방법이 필요함.

- 모델 평가의 핵심은 가용 데이터를 항상 훈련/검증/테스트 3개의 세트로 나누는 것임.
  훈련/검증 데이터세트는 훈련단계에서 사용하고, 테스트 데이터세트는 모델을 출시하기전에 최종적으로 딱 한번 테스트할때 사용함.

- 훈련단계에서 테스트 데이터세트를 사용하지 않는 이유는, 모델을 개발하는 단계에서는 항상 모델의 설정을 튜닝하기 때문임.  
  예를들어 층의 수나 층의 유닛수와 같은 하이퍼파라미터를 바꿔주는 작업들임.  
  즉, 검증 세트에서 모델의 성능을 평가하여 이런 하이퍼파라미터를 바꿔주면서 좋은 설정을 찾는것이 "학습" 임.  

- 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면, 검증 세트로 모델을 직접 훈련하지 않더라도 검증 세트에 대한 과대적합이 발생할수있음.  
  검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할때마다, 검증데이터에 대한 정보를 모델이 인식하기 때문임. (정보누설, information leak)  
  검증데이터에 대한 최적화를 피하기 위해서는 모델을 검증하는 단계에서 이전에 본적없는 완전히 다른 데이터를 사용해야 함.

- 대표적인 검증방법으로는 단순 홀드아웃 검증, K-겹 교차 검증, 셔플링 반복 K-겹 교차 검증 등이 있음.

- 단순 홀드아웃 검증 :  
  정보 누설을 막기 위해 전체 가용 데이터를 훈련세트와 홀드아웃 검증세트로 구분하는 방법임.  
  데이터가 적을때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할수도 있음.

- K-겹 교차 검증 :  
  데이터를 동일한 크기를 가진 K개의 분할로 나누고, 각 분할 i에 대해 남은 K-1 개의 분할들로 모델을 훈련하고 나머지 분할 하나로 검증하는 방법임.  
  이렇게 얻은 K 개의 점수를 평균해서 최종점수를 산출함.  
  모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 되는 방법임.  
  홀드아웃 검증처럼 모델의 튜닝에 별개의 검증세트를 사용해야함.

- 셔플링 반복 K-겹 교차 검증 :  
  K-겹 교차 검증을 여러번 적용하되, K개의 분할로 나누기전에 매번 데이터를 무작위로 섞는 방법임.  
  가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할때 사용함.  
  총 n회 * K개 만큼 모델을 훈련하고 검증하기 때문에 비용이 매우 많이 발생함.  

- 평가 방식을 선택할때 유념해야할 사항 :  
  - 대표성이 있는 데이터 :  
    주어진 데이터에 대한 대표성이 있어야 함.  
    예를들어 훈련세트에는 0~7 숫자만 담겨있고, 테스트세트에는 8~9 숫자만 담겨있으면 안됨.
  - 시간의 방향 :  
    과거로부터 미래를 예측하는 문제에서는 데이터를 분할하기전에 무작위로 섞어서는 안됨.
  - 데이터 중복 :  
    한 데이터세트에 같은 데이터포인트가 두번이상 등장하지 않도록 해야함.



## 4.3. 데이터 전처리, 특성 공학, 특성 학습

- 데이터 전처리의 목적은 주어진 원본데이터를 신경망에 적용하기 쉽도록 만드는것임.  
  벡터화, 정규화, 누락된 값 다루기, 특성추출 등이 있음.

- 벡터화(vectorization) :  
  신경망에서 모든 입력과 타깃은 부동소수데이터로 이루어진 텐서이어야 함.  
  사운드, 이미지, 텍스트 등 처리해야할것이 무엇이든지 먼저 텐서로 변환해야 함.

- 정규화(normalization) :  
  각 특성을 독립적으로 정규화하여 평균이 0 이고 표준편차가 1 이 되도록 만듬.  
  일반적으로는, 비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하는것이 위험하기 때문임.  
  업데이트할 그래디언트가 커져 네트워크가 수렴하는 것을 방해함.  
  어떻게 해야하나..?  
  => 작은값을 취해야함. 대부분의 값이 0~1 사이이어야 함.  
  => 균일해야 함. 모든 특성들이 대체로 비슷한 범위를 가져야 함.  

- 누락된 값 다루기 :  
  일반적으로는, 신경망에서 0 이 사전에 정의된 의미있는값이 아니라면 누락된 값을 0 으로 입력해도 괜찮음.  
  네트워크가 0 이 누락된 데이터를 의미한다는 것을 학습하면 이 값을 무시하기 시작함.  
  테스트데이터에는 누락값이 있는데 훈련데이터에는 없다면, 네트워크가 누락된 값을 무시하는 법을 알지 못하기때문에, 누락된 값이 있는 훈련샘플을 고의적으로 만들어야함.  

- 특성 공학 :  
  모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 만들어줌.  
  특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만드는것이 핵심임.  
  ※ 좋은 특성은 적은 자원을 사용해서 문제를 더 멋지게 풀어낼수있음. 예를들어 시계바늘을 읽는 문제에 합성곱신경망을 사용하는것은 어울리지 않음.  
  ※ 좋은 특성은 더 적은 데이터로 문제를 풀수있음. 딥러닝 모델이 스스로 특성을 학습하는 능력은 훈련데이터가 많을때 발휘됨. 샘플개수가 적으면 특성공학이 매우 중요해짐.



## 4.4. 과대적합과 과소적합

## 4.5. 보편적인 머신러닝 작업흐름

