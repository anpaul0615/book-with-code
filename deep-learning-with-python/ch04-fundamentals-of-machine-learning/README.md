# 4장 머신러닝의 기본 요소


## 4.1. 머신러닝의 네가지 분류

- 지도학습, 비지도학습, 자기지도학습, 강화학습

- 지도학습 :  
  샘플데이터가 주어지면 알고있는 타깃에 입력데이터를 매핑하는 방법을 학습하는 방법임.  
  광학문자판독, 음성인식, 언어번역 등 대부분의 딥러닝 응용분야가 지도학습 기반으로 구현됨.  
  대부분의 경우에 분류와 회귀로 구성되지만 시퀀스생성, 구문트리예측, 물체감지, 이미지분할 등 과 같은 특이한 변종도 있음.

- 비지도학습 :  
  어떠한 타깃도 사용하지 않고 입력데이터에 대한 흥미로운 변환을 찾는 방법임.  
  데이터에 있는 상관관계를 더 잘 이해하기 위해 사용함.  
  종종 지도학습 문제를 풀기 전에 데이터세트를 더 잘 이해하기 위해 필수적으로 거치는 단계로 사용됨.  
  차원축소, 군집 등이 비지도학습에서 잘 알려진 범주임.

- 자기지도학습 :  
  지도학습이지만, 사람이 만든 레이블을 사용하지 않는 지도학습임.  
  즉 학습과정에 사람이 개입하지 않는 지도학습.  
  경험적인 알고리즘을 사용해서 입력데이터로부터 생성된 레이블을 사용함.  
  예를들어 오토인코더(autoencoder), 지난 프레임이 주어졌을때 비디오의 다음 프레임을 예측하기, 이전단어가 주어졌을때 다음단어를 예측하기 등이 자기지도학습의 예임.  
  지도학습, 자기지도학습, 비지도학습 은 명확한 경계가 없고 연속적이기 때문에, 학습 메커니즘과 애플리케이션 측면 중 어디에 중점을 두는지에 따라 재해석될수있음.

- 강화학습 :  
  에이전트라는 학습 주체를 만들고, 이 에이전트를 환경에 대한 정보를 받아 보상을 최대한으로 얻는 행동을 선택하도록 학습시키는 방법임.  
  예를들어 비디오게임화면을 입력으로 받고, 게임점수를 최대화하는 행동을 학습하도록하여, 게임 내의 에이전트의 행동을 출력하도록 구성함.  
  아직까지 게임 이외의 실제적인 성공사례는 없지만, 앞으로 자율주행자동차, 자원관리, 교육 등에서 좋은 성과를 보일것으로 기대함.

- ※ 분류와 회귀에서 사용하는 용어 정리  
  샘플(=입력) : 모델에 주입될 하나의 데이터포인트  
  예측(=출력) : 모델로부터 나오는 값  
  타깃 : 모델이 완벽하게 예측해야 하는값  
  예측오차(=손실값) : 모델의 예측과 타깃 사이의 차이값  
  레이블 : 분류문제에서 클래스 할당의 구체적인 사례  
  클래스 : 분류문제에서 데이터포인트가 선택가능한 범주들의 집합



## 4.2. 머신러닝 모델 평가

- 머신러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는것임.  
  모델의 일반화 성능에 대한 신뢰할수있는 측정방법이 필요함.

- 모델 평가의 핵심은 가용 데이터를 항상 훈련/검증/테스트 3개의 세트로 나누는 것임.
  훈련/검증 데이터세트는 훈련단계에서 사용하고, 테스트 데이터세트는 모델을 출시하기전에 최종적으로 딱 한번 테스트할때 사용함.

- 훈련단계에서 테스트 데이터세트를 사용하지 않는 이유는, 모델을 개발하는 단계에서는 항상 모델의 설정을 튜닝하기 때문임.  
  예를들어 층의 수나 층의 유닛수와 같은 하이퍼파라미터를 바꿔주는 작업들임.  
  즉, 검증 세트에서 모델의 성능을 평가하여 이런 하이퍼파라미터를 바꿔주면서 좋은 설정을 찾는것이 "학습" 임.  

- 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면, 검증 세트로 모델을 직접 훈련하지 않더라도 검증 세트에 대한 과대적합이 발생할수있음.  
  검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할때마다, 검증데이터에 대한 정보를 모델이 인식하기 때문임. (정보누설, information leak)  
  검증데이터에 대한 최적화를 피하기 위해서는 모델을 검증하는 단계에서 이전에 본적없는 완전히 다른 데이터를 사용해야 함.

- 대표적인 검증방법으로는 단순 홀드아웃 검증, K-겹 교차 검증, 셔플링 반복 K-겹 교차 검증 등이 있음.

- 단순 홀드아웃 검증 :  
  정보 누설을 막기 위해 전체 가용 데이터를 훈련세트와 홀드아웃 검증세트로 구분하는 방법임.  
  데이터가 적을때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할수도 있음.

- K-겹 교차 검증 :  
  데이터를 동일한 크기를 가진 K개의 분할로 나누고, 각 분할 i에 대해 남은 K-1 개의 분할들로 모델을 훈련하고 나머지 분할 하나로 검증하는 방법임.  
  이렇게 얻은 K 개의 점수를 평균해서 최종점수를 산출함.  
  모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 되는 방법임.  
  홀드아웃 검증처럼 모델의 튜닝에 별개의 검증세트를 사용해야함.

- 셔플링 반복 K-겹 교차 검증 :  
  K-겹 교차 검증을 여러번 적용하되, K개의 분할로 나누기전에 매번 데이터를 무작위로 섞는 방법임.  
  가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할때 사용함.  
  총 n회 * K개 만큼 모델을 훈련하고 검증하기 때문에 비용이 매우 많이 발생함.  

- 평가 방식을 선택할때 유념해야할 사항 :  
  - 대표성이 있는 데이터 :  
    주어진 데이터에 대한 대표성이 있어야 함.  
    예를들어 훈련세트에는 0~7 숫자만 담겨있고, 테스트세트에는 8~9 숫자만 담겨있으면 안됨.
  - 시간의 방향 :  
    과거로부터 미래를 예측하는 문제에서는 데이터를 분할하기전에 무작위로 섞어서는 안됨.
  - 데이터 중복 :  
    한 데이터세트에 같은 데이터포인트가 두번이상 등장하지 않도록 해야함.



## 4.3. 데이터 전처리, 특성 공학, 특성 학습

- 데이터 전처리의 목적은 주어진 원본데이터를 신경망에 적용하기 쉽도록 만드는것임.  
  벡터화, 정규화, 누락된 값 다루기, 특성추출 등이 있음.

- 벡터화(vectorization) :  
  신경망에서 모든 입력과 타깃은 부동소수데이터로 이루어진 텐서이어야 함.  
  사운드, 이미지, 텍스트 등 처리해야할것이 무엇이든지 먼저 텐서로 변환해야 함.

- 정규화(normalization) :  
  각 특성을 독립적으로 정규화하여 평균이 0 이고 표준편차가 1 이 되도록 만듬.  
  일반적으로는, 비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하는것이 위험하기 때문임.  
  업데이트할 그래디언트가 커져 네트워크가 수렴하는 것을 방해함.  
  어떻게 해야하나..?  
  => 작은값을 취해야함. 대부분의 값이 0~1 사이이어야 함.  
  => 균일해야 함. 모든 특성들이 대체로 비슷한 범위를 가져야 함.  

- 누락된 값 다루기 :  
  일반적으로는, 신경망에서 0 이 사전에 정의된 의미있는값이 아니라면 누락된 값을 0 으로 입력해도 괜찮음.  
  네트워크가 0 이 누락된 데이터를 의미한다는 것을 학습하면 이 값을 무시하기 시작함.  
  테스트데이터에는 누락값이 있는데 훈련데이터에는 없다면, 네트워크가 누락된 값을 무시하는 법을 알지 못하기때문에, 누락된 값이 있는 훈련샘플을 고의적으로 만들어야함.  

- 특성 공학 :  
  모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 만들어줌.  
  특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만드는것이 핵심임.  
  ※ 좋은 특성은 적은 자원을 사용해서 문제를 더 멋지게 풀어낼수있음. 예를들어 시계바늘을 읽는 문제에 합성곱신경망을 사용하는것은 어울리지 않음.  
  ※ 좋은 특성은 더 적은 데이터로 문제를 풀수있음. 딥러닝 모델이 스스로 특성을 학습하는 능력은 훈련데이터가 많을때 발휘됨. 샘플개수가 적으면 특성공학이 매우 중요해짐.



## 4.4. 과대적합과 과소적합

- 과대적합..?  
  모델의 성능이 몇 번의 에포크 후에 최고치에 다다랐다가 감소되는 현상.

- 머신러닝의 근본적인 이슈는 최적화와 일반화의 줄다리기.

- 최적화(optimization)..?  
  가능한 훈련데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정.  

- 일반화(generalization)..?  
  훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지를 의미함.

- 모델을 만드는 목적은 좋은 일반화 성능을 얻는것임.  
  하지만 일반화 성능을 제어할 방법이 없음.  
  단지 훈련데이터를 기반으로 모델을 조정할수만 있음.

- 과소적합..?  
  훈련데이터의 손실이 낮아질수록 테스트데이터의 손실도 낮아지는 현상.  
  주로 훈련 초기에 보이며, 모델의 성능이 계속 발전될 여지가 있는 상황임. (네트워크가 훈련데이터의 특성을 모두 학습하지 못한 상태)

- 훈련데이터를 여러번 반복 학습하고 나면 어느시점부터 일반화 성능이 더이상 높아지지 않게되고, 검증세트의 성능이 멈추고 점점 감소되기 시작함.  
  이는 네트워크가 훈련데이트에 특화된 패턴을 학습하기 시작했다는 의미임.

- 모델이 관련성이 없고 좋지 못한 패턴을 훈련데이터에서 학습하지 못하도록 하려면..?  
  가장 좋은 방법은 더 많은 훈련데이터를 모으는것.  
  차선책은 모델이 수용할수있는 정보의 양을 조절하거나 저장할수있는 정보에 제약을 가하는것. (규제, regularization)

- 규제의 종류..?  
  네트워크 크기 축소, 가중치 규제, 드롭아웃

- 네트워크 크기 축소 :  
  과대적합을 막는 가장 단순한 방법은 모델의 크기, 즉 모델에 있는 학습 파라미터의 수를 줄이는것임.  
  항상 유념해야할것은 딥러닝 모델은 훈련데이터에 잘 맞추려는 경향이 있다는점임.  
  네트워크가 기억용량에 제한이 있다면 훈련데이터에 대한 매핑을 쉽게 학습하지 못할것임.  
  즉 손실을 최소화하기 위해 타깃에 대한 예측 성능을 가진 압축된 표현을 학습해야 하기때문임.  
  동시에 기억해야할것은 과소적합되지않도록 충분한 파라미터를 가진 모델을 사용해야 한다는점임.  
  너무 많은 용량과 충분하지 않은 용량 사이의 절충점을 찾아야함.

- 가중치 규제 :  
  네트워크의 복잡도에 제한을 두어 가중치가 작은값을 가지도록 강제하는 방법.  
  간단한 모델이 복잡한 모델보다 과대적합될 가능성이 낮기때문임.  
  - L1 규제 : 가중치의 절댓값에 비례하는 비용이 추가됨.
  - L2 규제 : 가중치의 제곱에 비례하는 비용이 추가됨. 가중치 감쇠(weight decay) 라고도 부름.
  쉽게말해서, 훈련과정에서 패널티항을 적용해서 네트워크의 손실을 더 많이 발생하도록함.

- 드롭아웃 :  
  훈련과정에서 무작위로 층의 일부 출력 특성을 제외시키는 방법. (0 으로 만듬)
  각 샘플에 대해 뉴런의 일부를 무작위하게 제거하여 누런의 부정한 협업을 방지함.  
  층의 출력값에 노이즈를 추가하여 중요하지 않은 우연한 패턴(부정한 협업) 을 깨뜨리는것이 핵심아이디어.



## 4.5. 보편적인 머신러닝 작업흐름

### 문제 정의와 데이터세트 수집

- 가장 먼저 해야할 일은 주어진 문제를 정의하는 것임.  
  - 입력데이터가 무엇인가? 어떤것을 예측하려고 하는가?  
    예를들어, 영화 리뷰와 감성 레이블이 태깅되어 있어야 영화 리뷰의 감성 분류를 학습할수있음.
  - 당면한 문제가 어떤 종류인가? (이진분류? 다중분류? 스칼라회귀? 벡터회귀? ..)  
    문제의 유형을 식별하면 모델의 구조와 손실함수 등을 선택하는데 용이함.

- 입력과 출력이 무엇인지와 어떤 데이터를 사용할것인지 확인한다음, 다음 두가지 가설을 세움.  
  1) 주어진 입력으로 출력을 예측할수있음  
  2) 가용한 데이터에 입력과 출력 사이의 관계를 학습하는데 충분한 정보가 있음

- 모델이 작동하기 전까지 가설은 가설일뿐.  
  입력 X와 타깃 Y의 샘플을 수집했다고해서, Y 를 예측하기에 충분한 정보가 X 에 있다는 말은 아님.

- 풀기 어려운 종류의 문제는 시간에 따라 변하는 문제임. (nonstationary problem)  
  시간에 따라 모델을 바꾸기 위해서는, 최근의 데이터를 기준으로 주기적으로 모델을 다시 훈련하거나, 시간 분포에 맞게 데이터를 수집하여 시간에 따라 변하지 않는 문제로 바꿔줘야 함.

- 미래를 예측하기 위해 과거데이터에서 훈련한 머신러닝을 사용하는 것은, 미래가 과거처럼 움직인다고 가정한 것임.  
  사실 대부분의 경우 그렇지 않음.


### 성공지표 선택

- 어떤 것을 제어하려면 관측할수있어야함. (=성공하기 위해서는 무엇이 성공인지를 정의해야함)  
  ex) 정확도? 정밀도? 재현율? 고객재방문율?

- 선정한 성공지표가 모델이 최적화할 손실함수를 선택하는 기준이 됨.

- 클래스분포가 균일한 분류문제에서는 정확도와 ROC AUC 가 일반적인 지표임.  
  클래스 분포가 균일하지 않은 문제에서는 정밀도와 재현율을 사용할수있음.  
  랭킹문제나 다중레이블문제에는 평균정밀도를 사용할수있음.  

- 성공을 측정하기 위해 자신만의 지표를 정의하는것은 좋지않음.  
  캐글 경연대회에서의 다양한 문제들과 측정지표들을 참고하는것이 좋은방법임.


### 평가방법 선택

- 홀드아웃 검증 세트 분리 : 데이터가 풍부할때 사용.  
  K-겹 교차 검증 : 홀드아웃 검증을 사용하기에 샘플수가 너무 적을때 사용.  
  반복 K-겹 교차 검증 : 데이터가 적은 상황에서 매우 정확한 모델 평가가 필요할때 사용.


### 데이터 준비

- 머신러닝 모델을 훈련시키기 위해서는 그전에 모델에 주입할 데이터를 구성해야함.

- 데이터 주입 준비
  1) 데이터는 텐서로 구성되어야함
  2) 이 텐서에 있는 값은 일반적으로 작은값으로 스케일이 조정되어야함
  3) 특성마다 범위가 다르면 정규화해야함
  4) 데이터가 적을때는 특성 공학을 수행할수있음


### 기본보다 나은 모델 훈련하기

- 통계적 검정력이란..?  
  우리가 세운 가설이 참일때 이를 채택할 확률을 의미함.  
  적어도 데이터세트에 있는 클래스별 분포도보다 모델의 정확도가 높아야 우리가 세운 가설이 옳다고 말할수있음.

- 통계적 검정력을 먼저 달성하기 위해, 아주 단순한 모델보다 조금 나은 수준의 작은 모델을 생성함.

- 통계적 검정력을 달성하는것이 항상 가능한것은 아님.  
  여러개의 타당성있는 네트워크 구조를 시도해보고 무작위로 예측하는 모델보다 낫지 않다면, 입력데이터에 없는 무언가를 얻으려고 한다는 신호임.  
  이는 처음에 세운 가설부터 잘못된것일수있으므로 기획부터 다시 시작해야함.

- 통계적 검정력을 달성했을때, 첫번째 모델을 만들기 위해 세가지 중요한 선택을 해야함.  
  1) 마지막층의 활성화 함수 : 네트워크의 출력에 필요한 제한을 적용함  
  2) 손실함수 : 풀려고 하는 문제의 종류에 적합해야함  
  3) 최적화설정 : 적절한 옵티마이저를 선정함  

- 손실함수가 주어진 문제의 성공지표를 직접 최적화하는 것이 항상 가능한것이 아님.  
  때로는 이 지표를 손실함수로 바꿀수있는 방법이 없을수도있음.  

- 손실함수는 주어진 배치 데이터 내에서 계산가능해야하고, 미분가능해야함.  
  이상적으로는 하나의 데이터포인트에서도 계산가능해야함.  
  역전파 알고리즘을 위해 미분가능한 함수이어야함.


### 몸집 키우기 : 과대적합 모델 구축

- 통계적 검정력을 가진 모델을 얻었다면, 이제는 모델이 충분한 성능을 내는지 확인해봐야함.

- 과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 적절히 위치한 모델이 이상적임.

- 얼마나 큰 모델을 만들어야 하는지 알기위해서는, 우선 과대적합된 모델을 먼저 만들어야함.  
  또한 훈련과 검증지표는 물론 항상 훈련손실과 검증손실을 모니터링해야함.  
  검증데이터에서 모델 성능이 감소하기 시작했을때가 과대적합이 시작되는 시점임.


### 모델 규제와 하이퍼파라미터 튜닝

- 반복적으로 모델을 수정하고 훈련하고 검증데이터에서 평가함.  
  가능한한 좋은 모델을 얻을때까지 반복함.  
  가장 많은 시간이 사용되는 단계.

- 시도해볼수있는 방법들  
  드롭아웃 추가  
  층을 추가하거나 제거해서 다른 네트워크 구조로 시도  
  L1 이나 L2 또는 두가지 모두 추가  
  최적의 설정을 찾기위해 하이퍼파라미터를 바꿔서 시도 (층의 유닛수나 옵티마이저의 학습률 등)  
  선택적으로 특성 공학을 시도 (새로운 특성을 추가하거나, 유용하지않을것같은 특성을 제거)

- 검증과정에서 얻은 피드백을 사용하여 모델을 튜닝할때마다 검증과정에 대한 정보가 모델에 누설됨.  
  이 과정을 반복하다보면 (모델이 검증데이터에 대해 전혀 훈련되지 않았는데도) 결국 모델이 검증데이터에 과대적합될수있음. 

- 만족할만한 모델 설정을 얻었다면, 가용한 모든 데이터를 사용해서 제품에 투입할 최종모델을 훈련시키고, 딱 한번 테스트세트에서 평가함.  
  만약 테스트세트에서의 성능이 검증데이터에서 측정한것보다 많이 나쁘다면, 검증과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 모델이 검증데이터에 과대적합되어 버린 상황임.  
  이런경우에는 좀 더 신뢰할만한 평가방법으로 바꾸는것이 좋음. (반복 K-겹 교차검증 등)

