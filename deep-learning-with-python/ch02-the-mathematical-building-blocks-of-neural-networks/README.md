# 2장 신경망의 수학적 구성 요소


## 2.1. 신경망과의 첫 만남

- [코드 실습 : MNIST 손글씨 숫자 이미지 분류](./mnist-demo.ipynb)

- 머신러닝에서 분류 문제의 범주(category) 를 클래스(class) 라고 함.  
  데이터 포인트는 샘플(sample) 이라고 함.  
  특정 샘플에 대한 클래스를 레이블(label) 이라고 함.

- 신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 층(layer) 이며,  
  이 층은 입력데이터로부터 의미있는 표현(representation) 을 추출함.

- 대부분의 딥러닝은 여러 층들이 연결된 구조로 되어 있고, 점진적으로 데이터를 정제하는 형태를 띄고있음.  
  즉 딥러닝 모델은 데이터 정제 필터인 층이 연속되어있는 "데이터 프로세싱을 위한 여과기" 라고 볼수있음.

- 완전 연결된(fully connected) 신경망 층인 Dense 층..?  
  이전 층의 출력을 입력으로 받는 층!

- 주로 신경망의 마지막에 위치해있는 소프트맥스(softmax) 층..?  
  손글씨 숫자 이미지를 최종적으로 분류하는 층!  
  마지막에 결론을 내는 층으로써 숫자 이미지 10개에 대한 확률 점수를 반환함,

- 신경망의 컴파일 단계에 포함되는 세가지 요소 :  
  손실 함수, 옵티마이저, 훈련과 테스트에 대한 평가 지표

- 손실 함수(loss function) :  
  훈련데이터에서 신경망의 성능을 측정하는 방법.  
  네트워크(모델) 가 올바른 방향으로 학습될 수 있도록 도와줌.

- 옵티마이저(optimizer) :  
  입력데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘임.

- 훈련과 테스트 과정을 모니터링할 지표 : 
  정확도(정확히 분류된 이미지의 비율) 등이 있음.

- 테스트 세트의 정확도가 훈련 세트 정확도보다 약간 낮게 나온 이유..?  
  과대적합 때문!

- 과대적합(overfitting) :  
  머신러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경항을 의미함.



## 2.2. 신경망을 위한 데이터 표현

- 텐서(tensor) 란..?  
  다차원 넘파이 배열  
  데이터를 위한 컨테이너(container)  
  임의의 차원 개수를 가지는 행렬의 일반화된 모습

- 텐서에서의 차원(dimension) == 텐서에서의 축(axis)

- 스칼라(0D 텐서) 란..?  
  하나의 숫자만 담고 있는 스칼라(scalar)  
  또는 스칼라 텐서, 0차원 텐서, 0D 텐서  
  스칼라 텐서의 축 개수는 0  

- 스칼라 텐서 예시
  ```python
  import numpy as np

  x = np.array(12)

  print(x)  ## array(12)
  print(x.ndim)  ## 0
  ```

- 텐서의 축 개수 == 랭크(rank)

- 벡터(1D 텐서) 란..?  
  숫자의 배열을(vector) 또는 1D 텐서  
  1D 텐서는 딱 하나의 축을 가짐

- 벡터 예시
  ```python
  x = np.array([12, 3, 6, 14, 7])

  print(x)  ## array([12, 3, 6, 14, 7])
  print(x.ndim)  ## 1
  ```

- 위 벡터는 5개의 원소를 가지고 있으므로 5차원 벡터라고 부름.  
  5D 벡터와 5D 텐서를 혼동하면 안됨.  
  5D 벡터는 하나의 축을따라 5개의 차원을 가진 것이고, 5D 텐서는 5개의 축을 가진 것임.

- 차원수(dimensionality) 란 특정 축을 따라 놓인 원소의 개수(ex. 5D 벡터) 이거나 텐서의 축 개수(ex. 5D 텐서) 를 의미함.

- 5D 텐서인 경우 랭크가 5 인 텐서라고 말하는것이 기술적으로는 좀 더 정확함. (텐서의 랭크 == 축의 개수)  
  그럼에도 5D 텐서 처럼 모호한 표기가 통용되고 있음.

- 행렬(2D 텐서) 이란..?  
  벡터의 배열을 행렬(matrix) 또는 2D 텐서 라고 부름.  
  행렬에는 2개의 축이 있음.  
  행렬은 숫자가 채워진사각 격자라고 생각하면 됨.

- 행렬 예시
  ```python
  x = np.array([[5, 78, 2, 34, 0],
                [6, 79, 3, 35, 1],
                [7, 80, 4, 36, 2]])

  print(x.ndim)  ## 2
  ```

- 위 행렬에서 x 의 첫번째 행은 `[5,78,2,34,0]` 이고, 첫번째 열은 `[5,6,7]` 임.

- 3D 텐서와 고차원 텐서..?  
  행렬(2D 텐서) 들을 하나의 새로운 배열로 합친것을 3D 텐서 라고 함.  
  3D 텐서는 숫자가 채워진 직육면체 형태로 해석할 수 있음.  
  3D 텐서들을 하나의 배열로 합친것을 4D 텐서 라고 함.  

- 3D 텐서 예시
  ```python
  x = np.array([[[5, 78, 2, 34, 0],
                  [6, 79, 3, 35, 1],
                  [7, 80, 4, 36, 2]],
                  [[5, 78, 2, 34, 0],
                  [6, 79, 3, 35, 1],
                  [7, 80, 4, 36, 2]]
                  [[5, 78, 2, 34, 0],
                  [6, 79, 3, 35, 1],
                  [7, 80, 4, 36, 2]]])

  print(x.ndim)  ## 3
  ```

- 텐서의 핵심 속성 : 축의 개수, 크기, 데이터 타입

- 축의 개수(랭크) :  
  넘파이의 ndim 속성에 저장됨.  
  ex) 3D 텐서에는 3개의 축, 행렬에는 2개의 축  

- 크기(shape) :  
  파이썬 튜플(tuple) 로 표현됨.  
  텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타냄.  
  ex) 위 행렬예시에서의 크기는 (3,5)  
  ex) 위 3D 텐서 예시에서의 크기는 (3,3,5)  
  ex) 위 벡터예시에서의 크기는 (5,)  
  ex) 위 스칼라예시에서는 크기가 없음  

- 데이터 타입 :  
  넘파이의 dtype 속성에 저장됨.  
  텐서에 포함된 데이터의 타입.  
  float32, unit8, float64 등이 될 수 있음.  
  드물게 char 타입을 사용하기도하지만 보통 가변 문자열 타입은 지원하지 않음.  
  (텐서는 사전에 할당되어 연속된 메모리에 저장되어야하기 때문)  
  ex) 위 행렬예시에서는 float32 타입

- 넘파이 배열에서 특정 원소들을 선택하는것을 슬라이싱(slicing) 이라고 함.  
  ex) `train_images[10:100]`  
  ex) `train_images[10:100, :, :]`  
  ex) `train_images[10:100, :28, :28]`  
  ex) `train_images[:, :14, :14]`  
  ex) `train_images[:, 7:-7, 7:-7]`  

- 일반적으로 딥러닝에서 사용하는 데이터 텐서의 첫번째 축을 샘플 축(sample axis) 또는 샘플 차원(sample dimension) 이라고 함.  
  ex) 이미지 데이터 텐서 : (samples, height, width, color_depth)  
  ex) 동영상 데이터 텐서 : (samples, frames, height, width, color_depth)  

- 딥러닝 모델은 데이터를 작은 배치(batch) 단위로 나누어서 전체 데이터세트를 처리함.  
  예를들어, MNIST 숫자 데이터에서 크기가 128 인 배치는  `batch = train_images[:128]` 로 표현되고, 그다음 배치는 `batch = train_images[128:256]` 이며, n 번째 배치는 `batch = train_images[128*n : 128*(n+1)]` 로 표현됨.

- 이런 배치 데이터를 다룰때는 첫번째 축을 배치 축(batch axis) 또는 배치 차원(batch dimension) 이라고 부름.

- 텐서의 실제 사례 :  
  벡터데이터 => (samples, features)  
  시계열데이터 => (samples, timesteps, features)  
  이미지데이터 => (samples, height, width, color_depth)  
  동영상데이터 => (samples, frames, height, width, color_depth)  

- 벡터 데이터(2D 텐서) :  
  첫번째 축은 샘플 축이고, 두번째 축은 특성 축  
  ex) 나이/우편번호/소득 으로 구성된 인구 통계 데이터에서, 각 사람은 3개의 값을 가진 벡터로 구성되고, 10만명이 포함된 전체 데이터 세트는 `(100000, 3)` 크기의 2D 텐서로 인코딩됨.  
  ex) 공통 단어 2만개와 각 단어가 등장한 횟수로 표현된 텍스트 문서 데이터세트에서, 각 문서는 2만개의 원소를 가진 벡터로 인코딩되고, 500개의 문서로 이루어진 전체 데이터세트는 `(500, 20000)` 크기의 2D 텐서로 인코딩됨.

- 시계열 데이터(3D 텐서) :  
  데이터에서 시간이나 연속된 순서가 중요할때는 시간축을 포함하여 3D 텐서로 구성함.  
  각 샘플은 벡터(2D 텐서)의 시퀀스로 인코딩 되므로, 배치 데이터는 3D 텐서로 인코딩 됨.  
  관례적으로 시간축은 항상 두번째 축(인덱스가 1번인 축) 으로 구성됨.  
  ex) 현재주식가격/지난1분간최고가격/최소가격 으로 구성된 주식 가격 데이터에서, 1분마다 데이터가 인코딩된다고 할때, 하루 거래시간 09:30~16:00 동안의 총 거래데이터는 `(390, 3)` 크기(형태)의 2D 텐서로 인코딩되고, 이 데이터의 250일치의 데이터는 `(250, 390, 3)` 크기의 3D 텐서로 저장될수있음.  
  ex) 128개의 알파벳과 280자의 문자시퀀스로 구성된 트윗 데이터에서, 각 문자는 128 크기인 이진벡터로 표현할수있고(원-핫인코딩), 이 문자데이터의 280자 조합으로 이루어진 트윗 데이터는 `(280, 128)` 크기의 2D 텐서로 인코딩될수있고, 100만개의 트윗으로 구성된 데이터세트는 `(1000000, 280, 128)` 크기의 텐서로 저장될수있음.

- 이미지 데이터(4D 텐서) :  
  이미지는 전형적으로 높이/너비/컬러 채널의 3차원으로 이루어짐.  
  흑백이미지는 하나의 컬러채널만을 가지고있어 2D 텐서로 저장될수도있지만, 관례상 이미지 텐서는 항상 3D 로 저장함. (흑백이미지인경우 컬러채널의 차원크기는 1, 그레이스케일)  
  ex) 256*256 크기의 흑백이미지에 대한 128개의 배치는 `(128, 256, 256, 1)` 크기의 텐서에 저장될수있음.  
  ex) 컬러이미지에 대한 128개의 배치는 `(128, 256, 256, 3)` 크기의 텐서에 저장될수있음.

- 동영상 데이터(5D 텐서) :  
  하나의 비디오는 프레임의 연속이고, 각 프레임은 하나의 컬러이미지와 동일함.  
  프레임은 `(height, width, color_depth)` 의 3D 텐서로 저장될수있으므로, 프레임의 연속은 `(frames, height, width, color_depth)` 의 4D 텐서로 저장될수있음.  
  여러 비디오의 매치는 `(samples, frames, height, width, color_depth)` 의 5D 텐서로 저장될수있음.  
  ex) 60초짜리 144*256 비디오클립을 초당 4프레임으로 샘플링한 240프레임/분 으로 된 비디오 데이터에서, 이 비디오클립을 4개 가진 배치는 `(4, 240, 144, 256, 3)` 크기의 5D 텐서에 저장됨.



## 2.3. 신경망의 톱니바퀴 : 텐서 연산

- 텐서 연산(tensor operation) :  
  신경망의 입력 또는 출력으로 사용되는 표현인 텐서에 대한 변환 작업  
  심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는데 사용됨.  
  ex) 텐서 덧셈, 텐서 곱셈, 점곱  

- 텐서 연산 구성 :  
  `output = relu( dot(W, input) + b)` 에서,  
  relu(x) 는 max(x, 0) 를 수행하는 함수  
  dot(a,b) 은 a 와 b 사이의 점곱  
  W 는 가중치, b 는 바이어스

- relu 함수는 원소별 연산(element-wise, operation) 으로 구분됨.  
  원소별 연산은 텐서에 있는 각 원소에 독립적으로 적용됨. (입력에 대한 원본을 유지)

- 브로드캐스팅(broadcasting) :  
  크기가 다른 두 텐서에 대해서, 작은 텐서가 큰 텐서의 크기에 맞추는 현상.

- 브로드캐스팅 동작 방식 :  
  1) 큰 텐서의 ndim 에 맞도록 작은 텐서에 브로드캐스팅 축이 추가됨.  
  2) 작은 텐서가 새 축을 따라서 큰 텐서의 크기만큼 반복해서 복사됨.  

- 브로트캐스팅 동작 방식 예시 :  
  (32,10) 텐서와 (10,) 텐서 사이에서 브로드캐스팅이 적용되면, 작은 텐서에 새 축이 하나 추가되고, 이 축을 따라서 작은 텐서를 큰 텐서의 첫번째 축 차원수만큼 작은텐서를 복사하면, (10,) 이 32 번 반복된 (32,10) 텐서가 만들어지게 됨.

- 텐서의 점곱(tensor produdct) :  
  입력 텐서의 원소들을 결함시킴.  
  점곱 연산 대상 원소들의 곱셈 결과값을 누적함. (새로운 스칼라)  
  x dot y 에서 x의 행의 크기와 y 의 열의 크기가 같아야함.  
  ex) 벡터와 벡터의 점곱 => 새로운 스칼라  
  ex) 행렬과 벡터의 점곱 => 새로운 벡터  
  ex) (a,b,c,d) dot (d,) => (a,b,c)  
  ex) (a,b,c,d) dot (d,e) => (a,b,c,e)  

- 텐서 크기 변환(tensor reshaping) :  
  주로 신경망에 주입할 숫자 데이터를 전처리할때 사용.  
  텐서의 크기를 변환한다는 것은 특정 크기에 맞게 열과 행을 재배열한다는 뜻임.  
  변환된 텐서는 원래의 텐서와 원소 개수가 동일함.  
  ```python
  x = np.array( [[0., 1.],
                [2., 3.],
                [4., 5.]] )
  print(x.shape)  ## (3,2)

  x = x.reshape( (6,1) )
  print(x)
  ## [[0.],
  ##  [1.],
  ##  [2.],
  ##  [3.],
  ##  [4.],
  ##  [5.]]

  x = x.reshape( (2,3) )
  print(x)
  ## [[ 0., 1., 2. ],
  ##  [ 3., 4., 5. ]]
  ```

- 자주 사용되는 크기 변환은 전치(transposition) 연산임.  
  행렬의 전치는 행과 열을 바꾸는 것을 의미함.  
  예를들어 x[i, :] 에서 x[:, i] 으로 변경되는 경우.  
  ```python
  x = np.zeros( (300,20) )
  print(x.shape)  ## (300,20)
  x = np.transpose(x)
  print(x.shape)  ## (20,300)
  ```

- 모든 텐서 연산은 기하학적 해석이 가능함.  
  예를들어 두 벡터를 더해서 나온 새로운 벡터를 좌표평면으로 표현.  
  텐서의 일반적인 기하학적 표현으로는 아핀변환, 회전, 스케일링 등이 있음.

- 신경망은 전체적으로 텐서 연산의 연결로 구성된 것이고, 모든 텐서 연산은 입력데이터의 기하학적 변환임.  

- 딥러닝의 기하학적 해석 예시 :  
  1) 빨간색 파란색 색종이 두장을 겹치고 뭉쳐서 하나의 작은 종이공으로 만들었을때, 이 종이공이 입력데이터고 색종이는 분류 클래스 임  
  2) 신경망이 해야할일은 이 종이공을 펼쳐서 두개의 분류 클래스로 깔끔하게 분리되는 변환을 찾는 것임  

- 위의 예시처럼, 종이공을 펼치는 것이 머신러닝이 하는일임.  
  즉, 복잡하고 심하게 꼬여있는 데이터의 매니폴드(다양체)에 대해서 깔끔한 표현을 찾는일임.

- 딥러닝은 기초적인 연산을 길게 연결하여 복잡한 기하학적 변환을 조금씩 분해하는 방식을 사용하는데, 이것이 마치 사람이 종이공을 펼치는 과정과 매우 흡사함.  
  심층 네트워크의 각 층은 데이터를 조금씩 풀어주는 변환을 수행하므로, 이런 층을 깊게 쌓으면 아주 복잡한 분해과정을 처리할수있음.  



## 2.4. 신경망의 엔진 : 그래디언트 기반 최적화

- 신경망의 각 층은 입력데이터를 다음과 같이 변환함.  
  `output = relu( dot(W, input) + b )`

- 위 식에서 텐서 W 와 b 를 가중치(weight) 또는 훈련되는 파라미터(trainable parameter) 라고 부름.  
  각각의 명칭은 W 는 커널, b 는 편향 이라고도 부름.  

- 이런 가중치에는 훈련데이터를 신경망에 노출시키서 학습된 정보가 담겨있음.  
  신경망의 피드백 신호에 기초하여 가중치가 점진적으로 조정되는 방식.

- 훈련 반복 루프(training loop) :   
  1) 훈련 샘플 x 와 이에 상응하는 타깃 y 의 배치를 추출함  
  2) x 를 사용하여 네트워크를 실행하고(정방향패스, forward pass 단계), 예측 y_pred 를 구함  
  3) y_pred 와 y 의 차이를 측정하여 이 배치에 대한 네트워크의 손실을 계산함  
  4) 배치에 대한 손실이 조금 감소되도록 네트워크의 모든 가중치를 업데이트함  

- 개별적인 가중치 값이 있을때 값이 증가해야할지 감소해야할지, 또 얼마나 업데이트해야할지 어떻게 할수있을까?

- 신경망에 사용된 모든 연산이 미분가능(differentiable) 하다는 장점을 사용함.  
  즉, 네트워크 가중치에 대한 손실의 그래디언트(gradient) 를 계산함.  
  계산된 그래디언트 값의 반대방향으로 가중치를 이동하면 손실이 감소됨.  

- 여기서 말하는 그래디언트는 텐서 연산의 변화율을 의미함.  
  즉 다차원 텐서를 입력으로 받는 함수에 변화율을 계산한다는 의미임.

- 입력벡터 x, 행렬 W, 타깃 y, 손실함수 loss 에서,  
  W 를 사용하여 타깃의 예측 y_pred 를 계산하고,  
  예측값 y_pred 와 실제값 y 사이의 오차값을 계산할수있음.
  ```python
  y_pred = dot(W, x)
  loss_value = loss(y_pred, y)
  ```

- x 와 y 가 고정되어 있다면, 오차값을 계산하는 함수는 W 를 손실값에 매핑하는 함수로 볼수있음.  
  ```python
  loss_value = f(W)
  ```

- 함수 f 의 변화율 함수를 gredient(f) 라고 했을때,  
  포인트 W0 에서의 f 의 변화율은 gredient(f)(W0) 임.

- 또한 `gredient(f)(W0)` 의 각 원소인 `gredient(f)(W0)[i, j]` 는  
  `W0[i, j]` 를 변경했을때 loss_value 가 바뀌는 방향과 크기를 나타냄.  (미분결과니까!)

- 다시말해서 텐서 `gredient(f)(W0)` 가 W0 에서의 함수 `f(W) = loss_value` 의 그래디언트가 됨.

- 그렇기 때문에 함수 f(W) 에 대해서 변화율의 반대 방향으로 조금 움직이면,  
  원래 변화해야하는 다음 단계가 아닌, 현재로 변화되기전 단계로 이동하게 되므로,  
  결과적으로 `f(W)` 의 값을 감소시킬수 있게 되는 것임.

- 미분가능한 함수가 주어지면 이론적으로 이 함수의 최솟값을 해석적으로 구할수있게됨.

- 어떤 함수의 최솟값은 변화율이 0 인 지점이므로,  
  변화율이 0 인 지점을 모두 찾아서 그 지점의 최소값을 확인하는것으로 전체 함수의 최솟값을 구할수있음.

- 이를 신경망에 적용하면, 가장 작은 손실함수의 값이 나오는 지점을 찾는것을 의미함.

- 하지만 실제 신경망에서는 파라미터의 개수가 수천개이므로 해석적으로 최솟값을 찾는것은 어려움.

- 그대신 랜덤한 배치데이터에서 현재 손실값을 토대로하여 조금씩 파라미터를 수정하는 방식을 사용할수있음.  
  미분가능한 함수를 가지고있으므로 그래디언트 계산을 통해 가중치를 조정해나가는 방식으로 훈련반복루프를 효율적으로 구현할수있음.

- 그래디언트 계산 기반 훈련 반복 루프 :   
  1) 훈련 샘플 x 와 이에 상응하는 타깃 y 의 배치를 추출함  
  2) x 를 사용하여 네트워크를 실행하고(정방향패스, forward pass 단계), 예측 y_pred 를 구함  
  3) y_pred 와 y 의 차이를 축정하여 이 배치에 대한 네트워크의 손실을 계산함  
  4) 네트워크의 파라미터에 대한 손실함수의 그래디언트를 계산함 (역방향패스, backwardpass)  
  5) 그래디언트의 반대방향으로 파라미터를 조금씩 이동시킴 (예를들어 `W -= step * gradient` 와 같이 배치에 대한 손실을 조금씩 줄임)

- 위 절차를 미니 배치 확률적 경사 하강법(mini-batch stochastic gradient desent, SGD) 이라고 함.

- 확률적(stochastic) 이란 표현은 무작위(random) 의 과학적 표현임.

- `W -= step * gradient` 에서는 적절한 step 값을 고르는것이 중요함.  
  값이 너무 작으면, 곡선을 따라 움직이는데 너무 많은 연산이 발생하고, 지역 최솟값(local minimum) 에 갇힐수있음.  
  또 값이 너무 크면, 함수 곡선에서 완전히 벗어나게 될수도있음.

- 실제로 경사하강법은 매우 고차원에서 사용됨.  
  신경망에 있는 각각의 가중치 값은 이 고차원 공간에서 하나의 독립적 차원으로 구성되어 있음.

- 따라서 저차원 표현으로 얻은 직관이 실전과 항상 맞지는 않는다는것을 유념해야함.  
  대표적인 사례로는, 오랫동안 신경망 알고리즘이 지역최솟값에 쉽게 갇힐것으로 생각했지만, 실제 고차원 공간에서는 각 손실값들이 대부분 안장점(saddle pooint) 으로 나타나고 지역최솟값은 매우 드물었음.

- 신경망의 가중치를 업데이트할때, 현재 그래디언트 값만 보지않고 이전에 업데이트된 가중치를 여러가지 다른 방식으로 고려하는 파생 SGD 들이 있음.
  특히 여러 파생 SGD 들에서 사용하는 모멘텀(momentum) 개념은 매우 중요한데, 모멘텀은 SGD 에 있는 2개의 문제점인 수렴속도와 지역최솟값을 해결해주기때문임.

- 예를들어, 어떤 파랄미터 값에서는 지역최솟값에 갇혀서 왼쪽으로 이동해도 오른쪽으로 이동해도 손실이 증가할수있음.  
  대상 파라미터가 작은 학습률을 가진 SGD 로 최적화되었다면, 최적화 과정이 전역최솟값으로 향하지 못하고 지역최솟값에 머무르게됨.

- 물리학에서 영감을 얻은 모멘텀을 사용하여 이 문제를 피할수있음.  
  최적화 과정을 손실 곡선 위로 작은 공을 굴리는것으로 생각할때, 모멘텀을 충분하게 만들면 공이 골짜기에 갇히지 않고 전역최솟값에 도달할수있음.  
  모멘텀은 현재 기울기 값(현재 가속도) 뿐만 아니라, 과거의 가속도로인한 현재 속도도 함께 고려해서 각 단계의 공을 움직임.  

- 실전에 적용할때는 현재 그래디언트 값 뿐만 아니라 이전에 업데이트한 파라미터에 기초하여 파라미터를 업데이트 하는 방식임.
  ```python
  past_velocity = 0.0  ## 과거 가속도
  momentum = 0.1  ## 모멘텀 상수

  while loss > 0.01 :  ## 최적화 반복 루프
    w, loss, gradient = get_current_parameters()
    velocity = (momentum * past_velocity) - (learning_rate * gradient)
    w += (momentum * velocity) - (learning_rate * gradient)
    past_velocity = velocity
    update_parameter(w)
  ```

- 모든 텐서 연산은 미분가능하며, 각 층의 입력은 그 전층의 출력이며, 각 층의 출력은 각 층의 텐서 연산의 결과임.  
  즉, 각 층의 출력은 이전 층의 텐서 연산 결과값이고, 이전 층의 텐서 연산의 입력 역시 그 이전층의  텐서 연산 결과값임.  
  
- 다시말해서 네트워크의 각 층의 텐서 연산은 이전 층의 출력과 현재 층의 입력으로 연결되어 있으므로,  
  연쇄 법칙(chain rule) 에 의해 `f(g(x))' = f'(g(x)) * g'(x)` 를 통해 유도됨.

- 연쇄 법칙을 신경망의 그래디언트 계사에 적용하여면,  
  역전파 알고리즘(Backpropagation) 또는 후진 모드 자동 미분(reverse-mode automatic differentiation) 을 구성할수있음.

- 역전파는 최종 손실값에서부터 시작함.  
  손실값에 각 파라미터가 기여한 정도를 계산하기 위해 연쇄 법칙을 적용하여 거꾸로 계산할수있음.

- 최근에는 기호 미분(symbolic differentiation) 을 사용하는 추세임.  
  변화율(도함수) 이, 알려진 연산들로 연결되어 있으면, 연쇄 법칙을 적용하여 네트워크 파라미터와 그래디언트 값을 매핑하는 그래디언트 함수를 계산할수있음.

- 이런 함수를 사용하면 역방향 패스는 그래디언트 함수를 호출하는것으로 단순화할수있음.



## 2.5. 첫 번째 예제 다시 살펴보기

- 입력데이터 전처리
  ```python
  (train_images, train_labels), (test_images, test_labels) = mnist.load_data()

  train_images = train_images.reshape((60000, 28*28))
  train_images = train_images.astype('float32') / 255

  test_images = test_images.reshape((10000, 28*28))
  test_images = test_images.astype('float32') / 255
  ```
  - 입력데이터는 이미지 데이터임.
  - 데이터타입은 float32, 훈련데이터는 (6000, 784) 크기, 테스트데이터는 (10000,784) 크기의 넘파이 배열로 구성됨.

- 신경망 구성
  ```python
  network = models.Sequential()
  network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))
  network.add(layers.Dense(10, activation='softmax'))
  ```
  - 네트워크(신경망) 은 두 개의 Dense 층이 연결되어 있는 구조임.
  - 각 층에서는 가중치 텐서와 입력데이터에 대한 텐서 연산을 수행함.
  - 가중치 텐서는 네트워크가 (학습결과에 따른) 정보를 저장하는곳임.

- 네트워크 컴파일
  ```python
  network.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
  ```
  - categorical_crossentropy 는 손실함수이며, 가중치 텐서에 대한 피드백 신호로 사용됨.
  - rmsprop 은 옵티마이저이며, 미니배치 확률적 경사하강법 적용 과정에서 네트워크 최적화를 수행함.

- 훈련 반복
  ```python
  network.fit(train_images, train_labels, epochs=5, batch_size=128)
  ```
  - 네트워크가 128개의 샘플단위로 나뉘어 훈련 절차를 진행하고, 그것을 총 5회 반복함
  - 전체 훈련데이터에 수행되는 각 반복을 에포크(epoch) 라고 함.
  - 각 반복마다 네트워크 배치에서 발생한 손실에 대한 그래디언트를 계산하고, 그에 맞추어 가중치를 업데이트함.
  - 총 60000개의 훈련데이터를 128사이즈의 미니배치로 나누면 총 469개의 배치가 만들어지고, 이를 5에포크만큼 반복하면 이 네트워크는 총 2,345회 만큼의 그래디언트 업데이트를 수행하게 됨.



## 2.6. 요약

- 학습이란, 훈련데이터 샘플과 그에 상응하는 타깃이 주어졌을때, 손실 함수를 최소화하는 모델 파라미터의 조합을 찾는것.

- 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고, 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행됨.

- 네트워크의 파라미터는 그래디언트의 반대방향으로 조금씩(학습률에 정의된 크기만큼) 움직임.

- 신경망이 미분가능한 텐서 연산으로 연결되어있는 성질을 이용해서, 현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해주는 그래디언트 함수를 구성하기 위해, 미분의 연쇄 법칙을 사용함.

- 손실과 옵티마이저는 네트워크에 데이터를 주입하기 전에 정의되어야함.

- 손실은 훈련하는 동안 최소화해야하며, 해결하려는 문제의 성공을 측정하는 기준으로 사용됨.

- 옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의함. (ex. RMSProp 옵티마이저, 모멘텀을 사용한 SGD 등)


