# 2장 신경망의 수학적 구성 요소


## 2.1. 신경망과의 첫 만남

- [코드 실습 : MNIST 손글씨 숫자 이미지 분류](./mnist-demo.ipynb)

- 머신러닝에서 분류 문제의 범주(category) 를 클래스(class) 라고 함.  
  데이터 포인트는 샘플(sample) 이라고 함.  
  특정 샘플에 대한 클래스를 레이블(label) 이라고 함.

- 신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 층(layer) 이며,  
  이 층은 입력데이터로부터 의미있는 표현(representation) 을 추출함.

- 대부분의 딥러닝은 여러 층들이 연결된 구조로 되어 있고, 점진적으로 데이터를 정제하는 형태를 띄고있음.  
  즉 딥러닝 모델은 데이터 정제 필터인 층이 연속되어있는 "데이터 프로세싱을 위한 여과기" 라고 볼수있음.

- 완전 연결된(fully connected) 신경망 층인 Dense 층..?  
  이전 층의 출력을 입력으로 받는 층!

- 주로 신경망의 마지막에 위치해있는 소프트맥스(softmax) 층..?  
  손글씨 숫자 이미지를 최종적으로 분류하는 층!  
  마지막에 결론을 내는 층으로써 숫자 이미지 10개에 대한 확률 점수를 반환함,

- 신경망의 컴파일 단계에 포함되는 세가지 요소 :  
  손실 함수, 옵티마이저, 훈련과 테스트에 대한 평가 지표

- 손실 함수(loss function) :  
  훈련데이터에서 신경망의 성능을 측정하는 방법.  
  네트워크(모델) 가 올바른 방향으로 학습될 수 있도록 도와줌.

- 옵티마이저(optimizer) :  
  입력데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘임.

- 훈련과 테스트 과정을 모니터링할 지표 : 
  정확도(정확히 분류된 이미지의 비율) 등이 있음.

- 테스트 세트의 정확도가 훈련 세트 정확도보다 약간 낮게 나온 이유..?  
  과대적합 때문!

- 과대적합(overfitting) :  
  머신러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경항을 의미함.



## 2.2. 신경망을 위한 데이터 표현

## 2.3. 신경망의 톱니바퀴 : 텐서 연산

## 2.4. 신경망의 엔진 : 그래디언트 기반 최적화

## 2.5. 첫 번째 예제 다시 살펴보기

## 2.6. 요약

