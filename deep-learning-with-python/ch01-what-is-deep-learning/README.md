# 1장 딥러닝이란 무엇인가?


## 1.1. 인공지능과 머신러닝, 딥러닝

### 1.1.1. 인공지능

- 인공지능이란..?  
  "**보통의 사람이 수행하는 지능적인 작업**" 을 "**자동화**" 하기 위한 연구활동.

- 프로그래머들이 명시적인 규칙을 충분하게 만들면 인간수준의 인공지능을 만들수 있다고 믿었음.  
  이런식의 접근방법을 심볼릭 AI (symbolic AI) 라고 함.


### 1.1.2. 머신러닝

- 머신러닝은 "어떤 것을 작동시키는 명령을 알고있는것 그 이상을 컴퓨터가 처리하는것이 가능한가?" "특정작업을 수행하는 법을 스스로 학습할 수 있는가?" "컴퓨터가 데이터를 보고 자동으로 이런 규칙을 학습할수 있을까?" 와 같은 질문에서부터 시작됨.

- 머신러닝에서는 데이터와 데이터로부터 기대되는 해답을 입력하면 규칙이 출력됨. 이 규칙을 새로운 데이터에 적용하여 창의적인 답을 만들수 있음.

- 머신러닝 시스템은 **명시적으로 프로그램되는것이 아니라 훈련(training) 을 통해 이루어짐.**  
  작업과 관련 있는 많은 샘플을 제공하면, 데이터에서 통계적 구조를 찾아 그 작업을 자동화하기 위한 규칙을 만들어내는 방식.

- 머신러닝은 통계와 달리 보통 대량의 복잡한 데이터세트를 다루기 때문에, 베이지안분석(Bayesian analysis) 와 같은 전통적인 통계분석방법을 적용하기 힘듬.  
  이런 이유 때문에 머신러닝 특히 딥러닝은 수학적 이론이 비교적 부족하고 엔지니어링 지향적임.  
  이런 실천적인 접근방식 때문에 **이론보다는 경험을 바탕으로 아이디어가 증명되는 경우가 많음.**


### 1.1.3. 데이터에서 표현을 학습하기

- 머신러닝은 샘플과 기댓값이 주어졌을때, 데이터 처리작업을 위한 실행규칙을 찾는것임

- 머신러닝 세 요소
  - **입력 데이터 포인트**  
    주어진 문제가 음성인식 문제에서는 사운드 파일  
    주어진 문제가 이미지 태깅 작업에서는 사진 파일
  - **기대 출력**  
    음석인식 문제에서는 사람잉 사운드 파일을 듣고 옮긴 글  
    이미지 작업에서는 '강아지' '고양이' 등과 같은 태그
  - **알고리즘의 성능을 측정하는 방법**  
    현재출력과 기대출력 간의 차이 측정  
    측정값을 기반으로 알고리즘을 교정

- 머신러닝의 핵심문제는 **"입력데이터를 의미있는 데이터로의 변환"** 하는 것임.
  다시말하면 입력데이터를 기반으로 기대출력에 가깝게 만드는 어떤 "표현(representation)" 을 학습하는 것임.

- 여기서의 **표현이란,** 데이터를 인코딩 하거나 묘사하기 위해 **데이터를 바라보는 다른 방법.**  
  ex) 컬러이미지를 RGB포맷이나 HSV포맷으로 표현할수있음

- 어떤 표현으로는 해결하기 힘든 문제가 다른 표현으로는 쉽게 해결할수도 있음.  
  ex) 이미지에 있는 모든 빨간색 픽셀을 선택하는 문제는 RGB포맷으로 쉽게 해결할수있음  
  ex) 이미지의 채도를 낮추는 문제는 HSV포맷이 더 쉬움

- 머신러닝에서의 학습이란, 더 나은 표현을 찾는 자동화된 과정임.  
  (현재출력과 기대출력을 비교해서 규칙을 갱신하는것도 학습임)

- 모든 머신러닝 알고리즘은 주어진 작업을 위해 데이터를 더 유용한 표현으로 바꾸는 작업을 자동으로 수행함.  
  수행하는 작업(연산)들은 좌표변환일수도 있고 또는 선형투영, 이동, 비선형연산 등이 될수도 있음.

- 머신러닝 알고리즘은 일반적으로 이런 변환을 찾기 위한 창의력은 없음.  
  가설공간(hypothesis space) 이라 부르는 미리 정의된 연산의 모음들을 자세히 조사하는 것 뿐임.  
  (즉, 이미 알고있는 변환 규칙들을 하나하나 대입해서 최적의 표현을 찾는다는 의미..?)


### 1.1.4. 딥러닝에서 '딥' 이란 무엇일까?

- 딥러닝은 머신러닝의 특정 한 분야로써, "연속된 층(layer)" 에서 점진적으로 의미있는 표현을 배우는데 강점이 있음.

- 데이터로부터 모델을 만드는데 얼마나 많은 층을 사용했는지가 그 모델의 "깊이" 가 됨.

- 딥러닝에서는 기본 층을 겹겹이 쌓아 올려 구성한 신경망(neural network)이라는 모델을 사용하여 표현 층을 학습함.

- 딥러닝은 그냥 데이터로부터 표현을 학습하는 수학 모델일 뿐임.

- (숫자분류 예시에서) **최종출력에 가까워질수록 원본 이미지와는 점점 더 다른 표현으로 숫자이미지가 변환됨.**  
  "심층 신경망" 을 정보가 연속된 필터를 통과하며서 순도높계 정제되는 "다단계 정보 추출 작업" 으로 생각할수도 있겠음.

- 층에서 입력데이터가 처리되는 상세내용은 "가중치(weight)" 에 저장되어 있음.  
  (기술적인 시각에서 봤을때, 어떤 층에서 일어나는 변환은 그 층의 가중치를  파라미터로 가지는 함수라고 볼수있음)


### 1.1.5. 그림 3개로 딥러닝의 작동 원리 이해하기

- 학습은 주어진 입력을 정확한 타깃에 매핑하기 위해, 신경망의 모든층에 있는 가중치 값을 찾는 것을 의미함.

- 신경망의 출력을 제어하려면, **출력이 기대하는 것보다 얼마나 벗어났는지를 측정**해야함.  
  이를 신경망의 손실함수(loss function) 이라고 함.

- 신경망이 한 샘플에 대해 얼마나 잘 예측했는지 측정하기 위해, 손실함수가 신경망의 예측과 진짜타깃의 차이를 점수로 계산함.

- 기본적인 딥러닝 방식은 이 점수를 피드백 신호로 사용하여 현재 샘플의 **손실점수가 감소되는 방향으로 가중치 값을 조금씩 수정**하는 것임.

- 샘플을 처리하면서 가중치가 조금씩 올바른 방향으로 조정되고, 손실점수는 점점 감소함.  
  이를 충분한 횟수만큼 반복하면 손실함수를 최소화하는 가중치 값을 산출할수있음.  
  **최소한의 손실을 내는 네트워크가 타깃에 가장 가까운 출력을 만드는 모델이 됨.**


### 1.1.6. 지금까지 딥러닝의 성과

- 딥러닝의 해결한 / 해결하고 있는 문제  
  이미지 분류, 음성 인식, 필기 인식, 기계 번역, TTS, 디지털 비서, 자율주행, 타게팅 광고, 검색엔진, 자연어 처리, 바둑


### 1.1.7. 단기간의 과대 선전을 믿지말자

- 단기간의 기대를 조금 누그러뜨리고, 딥러닝이 할수있는것과 할수없는것에 대해 명확히 이해해야함.


### 1.1.8. AI 에 대한 전망

- 단기간의 기대는 비현실적일지도 모르지만, 장기적인 전망은 매우 밝음.



## 1.2. 딥러닝 이전: 머신러닝의 간략한 역사

### 1.2.1. 확률적 모델링

- 확률적 모델링(probabilistic modeling) 은 통계학 이론을 데이터 분석에 응용한 것임.  
  초창기 머신러닝 형태 중 하나고 요즘도 널리 사용됨.

- 가장 잘 알려진 알고리즘 중 하나는 나이브 베이즈(Naive Bayes) 알고리즘임.  
  나이브 베이즈는 입력데이터의 특성이 모두 독립적이라고 가정하고 베이즈 정리(Bayes' theorem) 를 적용하는 머신러닝 "분류" 알고리즘임.

- 이와 밀접하게 연관된 모델이 로지스틱 회귀(logistic regression) 임.  
  로지스틱 회귀는 현대 머신러닝의 'hello world' 로 여겨지고 있음.  
  로지스틱 회귀는 회귀(regression) 알고리즘이 아니라 분류(classification) 알고리즘임.  
  데이터 과학자가 분류 작업에 대한 감을 빠르게 얻기 위해 데이터세트에 적용할 첫번째 알고리즘으로 사용하는 경우가 많음.

- 회귀는 연속적인 숫자(실수) 를 예측하는 것이고, 분류는 여러 클래스(class) 중 하나를 예측하는 것임.


### 1.2.2. 초창기 신경망

- 1980년대 중반 역전파 알고리즘을 재발견하고 신경망에 이를 적용하기 시작함.  
  역전파 알고리즘은 경사 하강법 최적화를 사용하여 연쇄적으로 변수가 연결된 연산을 훈련하는 방법임.


### 1.2.3. 커널 방법

- 커널 방법(Kernel method) 은 분류 알고리즘의 한 종류를 말하며, 서포트 벡터 머신(Support Vector Machin, SVM) 이 가장 유명함.

- SVM 은 분류 문제 뿐만아니라 회귀 문제 에서도 사용할 수 있음.

- SVM 은 분류 문제를 해결하기 위해, 2개의 다른 범주에 속한 데이터 포인트 그룹 사이에서, 좋은 결정 경계(decision boundary) 를 찾음.

- SVM 이 결정 경계를 찾는 과정.
  1) 결정 경계가 하나의 초평면(hyperplane) 으로 표현될수있도록 데이터를 매핑
  2) "초평면" 과 각 클래스의 "가장 가까운 데이터 포인트" 사이의 거리가, 최대가 되는 결정 경계를 찾음 (마진최대화)

- 분류 문제를 간단하게 만들어 주기 위해 데이터를 고차원 표현으로 매핑하는 기법이 이론상으로는 좋아보이지만,  
  실제 컴퓨터로 구현하기는 어려웠기 때문에 커널 기법(kernel trick) 이 등장함.

- 커널 기법에서는 새롭게 표현된 공간에서 좋은 결정 초평면을 찾기 위해 새로운 공간에 대응하는 데이터 포인트의 좌표를 실제로 구하지 않음.  
  커널 함수(kernel function) 를 통해 새로운 공간에서의 두 데이터 포인트 사이의 거리를 계산할 수만 있으면 됨.  

- 커널 함수는 원본 공간에 있는 두 데이터 포인트를 명시적으로 새로운 표현으로 변환하지 않고, 타깃 표현 공간에 위치했을때의 거리를 매핑해주는 연산임.  
  커널 함수는 일반적으로 데이터로부터 학습되지 않고 직접 만들어야함. SVM 에서 학습되는 것은 분할 초평면 뿐임.

- SVM 은 대용량의 데이터세트에 확장되기 어렵고 이미지분류 같은 지각에 관련된 문제에서 좋은 성능을 내지 못했음.  
  SVM 은 얕은 학습방법이기 때문에 지각에 관련된 문제에서는 학습전에 데이터세트에서 수동으로 유용한 표현을 추출해야함.


### 1.2.4. 결정 트리, 렌덤 포레스트, 그래디언트 부스팅 머신

- 결정 트리(decision tree) 는 플로우차트(flowchart) 같은 구조를 가지며, 입력 데이터 포인트를 분류하거나 주어진 입력에 대해 출력 값을 예측함.

- 렌덤 포레스트(Random Forest) 알고리즘은 결정 트리 학습에 기초한 것으로, 서로 다른 결정 트리를 만들고 그 출력을 앙상블하는 방법을 사용하는 기법임.

- 그래디언트 부스팅 머신(gradient boosting machine) 은 약한 예측 모델인 결정 트리를 앙상블하는 것을 기반으로 하는 머신러닝 기법임.  
  그래디언트 부스팅 머신은 **이전 모델에서 놓친 데이터 포인트를 보완하는 새로운 모델을 반복적으로 훈련함으로써 머신러닝 모델을 향상**시키는 방법인 그래디언트 부스팅(gradient boosting) 을 사용함.


### 1.2.5. 다시 신경망으로

- 2011년 심층 신경망(deep neural network) 가 학술 이미지 분류 대회에서 우승함.

- 이어서 2012년 ImageNet 에서 정확도 83.6% 를 달성함.  
  이때부터 매년 심층 합성곱 신경망(deep convolutional neural network, ConvNet) 이 우승을 차지했음.

- 2012년부터 심층 합성곱 신경망이 모든 컴퓨터 비전 작업의 주력 알고리즘이 되었음.

- 동시에 딥러닝은 자연어 처리(natural language processing) 같은 다른 종류의 문제에도 적용되었음.


### 1.2.6. 딥러닝의 특징

- 딥러닝은 머신러닝에서 가장 중요한 단계인 특성 공학을 완전히 자동화하기 때문에 문제를 더 해결하기 쉽게 만들어줌.

- 기존 머신러닝 시스템에서는, 머신러닝 시스템이 처리하기 용이하게 사람이 초기 입력 데이터를 여러 방식으로 변환해야 했음.  
  즉 데이터의 좋은 표현을 수동으로 만들어야 했음.
  이를 특성 공학(feature engineering) 이라고 함.

- 그에 반해 딥러닝은 이 단계를 완전히 자동화 함.  
  **딥러닝에서는 특성을 직접 찾는 대신 한 번에 모든 특성을 학습할 수 있음.**  
  고도의 다단계 작업 과정을 하나의 간단한 엔드-투-엔드 딥러닝 모델로 대체할수있음.

- 얕은 학습 방법은 연속된 표현 층을 독립적으로 학습하기 때문에, 전체 층의 개수와 상관없이 항상 동일하게 첫번째 층이 동일한 양의 정보를 학습하므로, 이후에 연속되는 층은 전체 모델에 기여하는 바가 점차 줄어듬.

- 딥러닝의 변환 능력은 모델이 모든 표현층을 순차적이 아니라 동시에 공동으로 학습하게 만듬.  
  이로 인해 **모델이 내부 특성 하나에 맞추어질때마다 이에 의존하는 다른 모든 특성들이 자동으로 변화에 적응**하게 됨.

- 딥러닝이 데이터로부터 학습하는 방법에는 두가지 중요한 특징이 있음.  
  1) 층을 거치면서 점진적으로 더 복잡한 표현이 만들이지는것  
  2) 이런 점진적인 중간표현이 공동으로 학습됨 (각 층은 상위 층과 하위 층의 표현이 변함에 따라서 함께 변화함)  


### 1.2.7. 머신러닝의 최근 동향

- 요즘 머신러닝 알고리즘과 도구의 동향에 대한 정보를 얻는 좋은 방법은 캐글의 머신러닝 경연을 살펴보는 것임.

- 오늘날 머신러닝을 성공적으로 적용하기 위해 알아야 할 두가지 기술은,  
  **"얕은 학습 문제를 위한 그래디언트 부스팅 머신"** 과 **"지각에 관한 문제를 위한 딥러닝"**


## 1.3. 왜 딥러닝일까? 왜 지금일까?

### 1.3.1. 하드웨어

- 다양한 병렬 애플리케이션의 대형 CPU 클러스터가 소량의 GPU 로 대체되기 시작함.

- 대부분의 많은 수의 간단한 행렬 곱셈으로 구성된 심층 신경망도 높은 수준으로 병렬화가 가능해짐.


### 1.3.2. 데이터

- 플리커(Flickr) 에서 사용자가 붙인 이미지 태그는 컴퓨터 비전의 입장에서는 보물 같은 데이터임.  
  유튜브(Youtube) 비디오도 마찬가지임.  
  위키피디아(Wikipedia) 는 자연어 처리 분야에 필요한 핵심 데이터세트임.  


### 1.3.3. 알고리즘

- 2000년대 후반까지는 매우 깊은 심층 신경망을 훈련시킬 수 있는 안정적인 방법을 찾지 못했음.  
  깊게 쌓은 층을 통과해서 그래디언트(gradient) 를 전파하는 것이 가장 문제였음.

- 2009~2010년경에 중요한 알고리즘이 개선되면서 그래디언트를 더 잘 전파되게 만들어 주었음.  
  1) 신경망의 층에 더 잘 맞는 **활성화 함수(activation function)**  
  2) 층별 사전 훈련(pretraining) 을 불필요하게 만든 **가중치 초기화(weight initialization) 방법**  
  3) RMSProp 과 Adam 같은 더 좋은 **최적화 방법**

- 이런 기술의 향상으로 10개 이상의 층을 가진 모델을 훈련시킬수 있게 되었을때 비로소 딥러닝이 빛을 발하기 시작함.

- 2014~2016년 사이에 그래디언트를 더욱 잘 전파할 수 있는 배치 정규화(batch normalization), 잔차 연결(residual connection), 깊이별 분리 합성곱(depthwise separable convolution) 같은 고급 기술들이 개발되었음.


### 1.3.4. 새로운 투자의 바람

- 2013년 구글은 5억달러에 딥러닝 스타트업인 딥마인드(DeepMind) 를 인수했음.  
  이는 AI 역사상 가장 큰 금액의 인수였음.


### 1.3.5. 딥러닝의 대중화

- 초창기에 딥러닝을 하려면 흔치 않은 C++ 과 CUDA 의 전문가가 되어야 했음.

- 요즘에는 기본 파이썬 스크립트 기술만 있으면 고수준의 딥러닝을 연구하는 데 충분함.  
  대부분 씨아노(Theano) 와 텐서플로(TensorFlow) 가 개발된 덕분임.


### 1.3.6. 지속될까?

- 딥러닝의 중요한 특징 세가지
  1) 단순함
  2) 확장성
  3) 다용도와 재사용성

- 단순함
  딥러닝은 특성 공학이 필요하지 않아 (..) 복잡했던 엔지니어링 과정을 엔드-투-엔드 로 훈련시킬수있는 모델로 만들어줌.  

- 확장성  
  딥러닝은 **GPU 또는 TPU 에서 쉽게 병렬화**할 수 있기 때문에 무어의 법칙 혜택을 크게 볼 수 있음.  
  또 딥러닝 모델은 작은 배치(batch) 데이터엥서 반복적으로 훈련되기때문에 **어떤 크기의 데이터세트에서도 훈련될 수** 있음.

- 다용도와 재사용성  
  이전의 머신러닝 방법과는 다르게 딥러닝 모델은 **처음부터 다시 시작하지 않고 추가되는 데이터만으로도 훈련할 수** 있음.  
  더불어 훈련된 딥러닝 모델은 **다른 용도로 재사용할 수도** 있음. 예를 들어 이미지 분류를 위해 훈련된 딥러닝 모델을 비디오 처리 작업 과정에 투입하는 경우임. 더 복잡하고 강력한 모델을 만들기 위해 이전의 작업을 재활용할 수도 있음.  
  또한 딥러닝 모델은 **아주 작은 데이터세트에도 적용할 수 있음.**

